# scripts/evaluate.py
# -*- coding: utf-8 -*-
"""
í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- ì €ì¥ëœ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/ì„ê³„ê°’ ë¡œë“œ
- ë™ì¼ ë°ì´í„°ë¡œ í”¼ì²˜ ìƒì„± + ì‹œê³„ì—´ ë¶„í• 
- í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ìµœì¢… ì„±ëŠ¥ ê³„ì‚°
- SHAP ë¶„ì„ ìˆ˜í–‰ ë° í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥
- ë¦¬í¬íŠ¸/í˜¼ë™í–‰ë ¬/AUPRC/ì„ê³„ê°’ ì €ì¥(outputs/metrics)
- ëˆ„ìˆ˜ ì ê²€(ë¼ë²¨ ì…”í”Œ) ê²°ê³¼ë„ ì¶œë ¥
"""


import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


from pathlib import Path
import argparse
import json
import numpy as np
import pandas as pd
from joblib import load
from src import load_paysim, time_split, outputs_ready
from src.features import build_features, align_to_feature_space
from src.evaluation import evaluate_at, save_metrics, sanity_label_shuffle
from src.modeling import predict_proba
from src.xai import get_explainer, explain, save_shap_features_csv, generate_individual_explanations, save_individual_shap_plots

def main(args):
    paths = outputs_ready()

    # 1) ë°ì´í„°/í”¼ì²˜/ë¶„í• 
    df = load_paysim()
    X_all, y_all, fspace = build_features(df)

    # ì¶”ë¡  ì»¬ëŸ¼ ì •ë ¬(í˜¹ì‹œë‚˜ë¥¼ ëŒ€ë¹„)
    (X_tr, y_tr), (X_va, y_va), (X_te, y_te) = time_split(X_all, y_all)
    X_te = align_to_feature_space(X_te.copy(), fspace)

    # 2) ì•„í‹°íŒ©íŠ¸ ë¡œë“œ
    model = load(paths.models / "model.joblib")
    scaler = load(paths.models / "scaler.joblib")
    best_thr = float((paths.models / "threshold.txt").read_text())

    # 3) ìŠ¤ì¼€ì¼ë§ í›„ ì˜ˆì¸¡
    X_te_s = pd.DataFrame(scaler.transform(X_te), columns=X_te.columns, index=X_te.index)
    y_proba = predict_proba(model, X_te_s)

    # 4) í‰ê°€
    er = evaluate_at(y_te.values, y_proba, best_thr)
    saved = save_metrics(result=er, out_dir=paths.metrics)

    # ì›í•œë‹¤ë©´ proba/ì˜ˆì¸¡ë„ ì €ì¥
    np.savetxt(paths.metrics / "y_proba_test.csv", y_proba, delimiter=",")
    np.savetxt(paths.metrics / "y_pred_test.csv", er.y_pred, fmt="%d", delimiter=",")

    # 5) SHAP ë¶„ì„ ìˆ˜í–‰ ë° í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥
    print("ğŸ” SHAP ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
    try:
        explainer = get_explainer(model)
        explanation, shap_matrix, feature_names = explain(explainer, X_te_s)
        
        # SHAP í”¼ì²˜ ì¤‘ìš”ë„ CSV ì €ì¥
        shap_csv_path = paths.figures / "shap_feature_importance.csv"
        save_shap_features_csv(shap_matrix, feature_names, shap_csv_path)
        print(f"âœ… SHAP í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥: {shap_csv_path}")
        
        # ê°œë³„ ê±°ë˜ SHAP ì„¤ëª… ìƒì„±
        print("ğŸ” ê°œë³„ ê±°ë˜ SHAP ì„¤ëª… ìƒì„± ì¤‘...")
        y_pred = (y_proba > best_thr).astype(int)
        individual_explanations = generate_individual_explanations(
            shap_matrix, X_te_s, y_pred, y_te.values, sample_size=5, k=5
        )
        
        # ê°œë³„ ê±°ë˜ SHAP ì‹œê°í™” ì €ì¥
        print("ğŸ“Š ê°œë³„ ê±°ë˜ SHAP ì‹œê°í™” ì €ì¥ ì¤‘...")
        sample_indices = [exp['transaction_id'] for exp in individual_explanations[:3]]  # ìƒìœ„ 3ê°œë§Œ ì‹œê°í™”
        individual_plot_paths = save_individual_shap_plots(
            explanation, X_te_s, sample_indices, paths.figures, prefix="individual_shap"
        )
        print(f"âœ… ê°œë³„ ê±°ë˜ SHAP ì‹œê°í™” ì €ì¥: {len(individual_plot_paths)}ê°œ íŒŒì¼")
        
        # SHAP ì‹œê°í™”ë„ ì €ì¥
        from src.xai import save_plots_bar_beeswarm
        plot_paths = save_plots_bar_beeswarm(explanation, paths.figures, prefix="shap")
        print(f"âœ… SHAP ì‹œê°í™” ì €ì¥: {plot_paths}")
        
    except Exception as e:
        print(f"âš ï¸ SHAP ë¶„ì„ ì‹¤íŒ¨: {e}")

    # 6) ëˆ„ìˆ˜ ì ê²€(ì…”í”Œ)
    sanity = sanity_label_shuffle(y_te.values, y_proba)
    (paths.metrics / "sanity_shuffle.json").write_text(json.dumps(sanity, indent=2, ensure_ascii=False))

    print(f"[eval] AUPRC={er.auprc:.6f}, threshold={er.threshold:.6f}")
    print(f"[eval] saved metrics â†’ {saved}")
    print(f"[eval] leakage_ok={sanity['ok']} | sanity={sanity}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    args = parser.parse_args()
    main(args)
